---
title: "CCM_san_nic"
author: "Owen Liu"
date: "May 20, 2016"
output: html_document
---

```{r setup, include=FALSE}
library(ggplot2)
library(tidyr)
library(dplyr)
library(reshape2)
library(vegan)
library(rgdal)
library(tseries)
library(rEDM)

#### Data ####
#note: all raw data has a .dat
W_D <- getwd()

# benthic species density
#**************************************
benthdens.dat <- read.csv(file=paste(W_D,'/data/Benthic density raw data.csv',sep=''))
#fix dates in the datasets to be more readable by R
betterDates <-function(dat) {
  dates<-as.Date(as.character(dat$Date),format="%m/%d/%y")
  return(dates)
}
benthdens.dat$Date <- betterDates(benthdens.dat)
#**************************************

# Species Key
#*************************************
spp.key <- read.csv(file=paste(W_D,'/data/Table4_Species_sampled.csv',sep='')) # All species, all surveys
spp.key.bdens <- spp.key[spp.key$DataSet=="Benthic density",] # just benthic density surveys
# better names
spp.key.bdens$name <- c("pat","red","purp","wavy","astro","derm","halc","halr","limp","paras","pis","pyc","cys","lam","ymac","youn","eis","pter","mac")
#**************************************

# Otter data
#***********************************
ott <- read.csv(file=paste(W_D,"/data/Table2_independent_sea_otters.csv",sep=""))
ott$Date<-as.Date(ott$Date,format="%m/%d/%Y")
# Have to manually match otter counts to periods in the benthic data, and assume population statis between periods when otters weren't counted
ott.counts.west <- c(rep(0,29),rep(10,3),9,rep(13,4),18,18,rep(20,3),24,22,20,20,30,29,29,29,29,31,31,18,18,30,34,42)
ott.counts.north <- c(rep(0,29),rep(4,3),5,rep(1,9),0,1,rep(0,7),1,1,0,0,1,4,0)
ott.counts.south <- c(rep(0,32),3,rep(0,4),2,2,rep(0,3),3,6,13,13,2,2,2,2,2,5,5,19,19,2,8,6)
ott.abun.key <- data.frame(period=sort(unique(benthdens.dat$Period)),west=ott.counts.west,north=ott.counts.north,south=ott.counts.south)

# ***********************************
# Replace species code with species name and rename some variables
benthdat <- benthdens.dat %>% 
  rename(station=Station,period=Period,date=Date,swath=Swath,dens=Density) %>%
  left_join(select(spp.key.bdens,SpeciesCode,name),by="SpeciesCode") %>%
  
  # remove unneeded columns
  select(-SpeciesCode,-date) %>%
  rename(spp=name) %>%
  arrange(spp,period,swath) %>%
  
  # join station and swath columns into one unique 'site' identifier
  unite(site,station,swath)

#*************************************
# There's one more problem, which is that there are some periods which were not sampled. It's better to make those values NAs in the data than just skipping over time periods.  This set of code expands the timeseries for each site/species to include NA density values for missing survey times.

periods.all <- data_frame(period=1:63)
sites <- sort(unique(benthdat$site))
spps <- sort(unique(benthdat$spp))
benthdat.full <- data_frame()
for(i in 1:length(sites)) {
  for(j in 1:length(spps)) {
    temp <- benthdat %>% filter(site==sites[i],spp==spps[j])
    temp <- full_join(periods.all,temp,by="period") %>% mutate(site=sites[i],spp=spps[j])
    benthdat.full <- bind_rows(benthdat.full,temp)
  }
}

```

Convergent cross mapping of the time series.  Based on Sugihara et al. 2012 Science; and Clark et al. 2015 Ecology.  First we run simplex analysis to establish embedding dimension for each species.  Then we can look for nonlinearity and cross mapping.  Because the San Nicolas data is split into periods and swaths, we'll take advantage of all the data we can for each species by constructing library vectors from all records of all swaths within a station, making sure not to construct library vectors spanning two different swaths.

```{r simplex and smap}

spp.simplex.smap <- function(species, stations=c(1:7), plotout = TRUE) {
  
  # all data for a particular species
  spp.dat <- filter(benthdat.full, spp==species) %>%
    
    # select only some stations (if applicable)
    separate(site,into=c("station","swath"),sep="_",remove=FALSE) %>%
    filter(station %in% stations) %>%
    arrange(site,period)
  
  # we need a record of the segments (indices of the beginning and end of each timeseries), so that simplex and s-map do not produce library or prediction vectors that span separate timeseries. This 2-column matrix denotes the row indices of the first and last record in each timeseries.
  
  segments <- spp.dat %>% mutate(ind = row_number()) %>% group_by(site) %>% summarise(first=first(ind),last=last(ind))
  
  # Now we can produce a random set of half of the segments for prediction, and use the others for the library
  rndlib <- segments %>% sample_frac(0.5,replace=F) %>% arrange(first) %>% select(-site)
  rndpred <- anti_join(segments,rndlib,by=c("first","last")) %>% arrange(first) %>% select(-site) # prediction vectors and library vectors mutually exclusive
  rndlib <- as.matrix(rndlib)
  rndpred <- as.matrix(rndpred)
  
  # composite timeseries (just year and data)
  ts.mat <- as.matrix(select(spp.dat,period,dens))
  
  # Now we can finally run simplex and s-map.
  # A NOTE HERE: using option exclusion_radius allows us to also remove from the library for each prediction the concurrent years' data from the other pooled timeseries, reducing overestimation due to spatial autocorrelation. For now we'll use an exclusion radius of 1 (for simplex) and min(3,E) for smap.
  spp.simplex <- simplex(ts.mat,lib=rndlib,pred=rndpred,E=c(2:8))
  if(plotout) {
    plot(spp.simplex$E,spp.simplex$rho,type="l",xlab="Embedding Dimension (E)",ylab="Forecast Skill(rho)",main=species)
  }
  
  # find best E from simplex output
  bestE <- spp.simplex$E[which(spp.simplex$rho==max(spp.simplex$rho))]
  print(paste("Best embedding dimension is",bestE))
  
  # Prediction decay check (checking for the butterfly effect)
  spp.tp.test <- simplex(ts.mat,lib=rndlib,pred=rndpred,E=bestE,tp=1:10)
  if(plotout) {
    plot(spp.tp.test$tp,spp.tp.test$rho,type="l",xlab="Prediction Horizon (tp)",ylab="Forecast Skill(rho)",main=species)
  }
  
  # Good forecast skill, and best E (best embedding dimension) recorded.  Now we can s-map to look for nonlinearity
  spp.smap <- s_map(ts.mat,lib=rndlib,pred=rndpred,E=bestE,exclusion_radius = 1)
  if(plotout) {
    plot(spp.smap$theta,spp.smap$rho,type="l",xlab="Nonlinearity (theta)",ylab="Forecast Skill(rho)",main=species)
  }
  out <- list(bestE=bestE,simp = spp.simplex,tp=spp.tp.test,smap = spp.smap)
  return(out)
}

```

Let's apply this to a subset of species in the San Nic dataset.  Let's look for species without too many zeroes, so the dynamics aren't weirdly skewed.

```{r apply simp and smap}
# What proportion of zeroes in the data for each species/site?
numzeroes <- benthdat.full %>% group_by(spp) %>% filter(dens==0) %>% summarise(zeroes=n())
propzeroes <- benthdat.full %>% group_by(spp) %>% 
  filter(dens != 0) %>% 
  summarise(nonzeroes=n()) %>%
  left_join(numzeroes, by="spp") %>%
  mutate(propzeroes=(zeroes/(nonzeroes+zeroes))) %>%
  arrange(propzeroes)

usable.spp <- propzeroes$spp[1:14]

# Lists to store simplex and smap output for each species
spp.simp.list <- list()
bestE <- data_frame(species = usable.spp,E=NA)
spp.tp.list <- list()
spp.smap.list <- list()

for(i in 1:length(usable.spp)) {
  sppname <- usable.spp[i]
  temp <- spp.simplex.smap(species=usable.spp[i],plotout=FALSE)
  spp.simp.list[[sppname]] <- temp$simp
  spp.tp.list[[sppname]] <- temp$tp
  spp.smap.list[[sppname]] <- temp$smap
  bestE[i,"E"] <- temp$bestE
  rm(temp)
}

# plot simplex output
par(mfrow=c(2,2))

for(i in 1:length(spp.simp.list)) {
  sppname <- names(spp.simp.list)[i]
  df <- spp.simp.list[[i]]
  plot(df$E,df$rho,type="l",xlab="Embedding Dimension (E)",ylab="Forecast Skill(rho)",main=paste(sppname,"simplex"))
}

#plot prediction horizons
plot.new()
for(i in 1:length(spp.tp.list)) {
  sppname <- names(spp.tp.list)[i]
  df <- spp.tp.list[[i]]
  plot(df$tp,df$rho,type="l",xlab="Prediction Horizon (tp)",ylab="Forecast Skill(rho)",main=paste(sppname,"prediction decay"))
}
# plot smap output
plot.new()

for(i in 1:length(spp.smap.list)) {
  sppname <- names(spp.smap.list)[i]
  df <- spp.smap.list[[i]]
  plot(df$theta,df$rho,type="l",xlab="Nonlinearity (theta)",ylab="Forecast Skill(rho)",main=paste(sppname,"smap"))
}
par(mfrow=c(1,1))
```

To do cross-mapping, it really helps to have the data organized in a way such that the time indices are all the same across all species.  So here, we'll make a large composites timeseries with the appended timeseries from all sites, but with columns being species.  We can use this composite for multivariate prediction and cross-mapping.

```{r composite timeseries}
composite.ts <- filter(benthdat.full, spp %in% usable.spp) %>%
  dcast(period + site ~ spp,value.var="dens") %>%
  arrange(site)
```

Now we have vertically "stacked" timeseries across species.  Time to run CCM.  For these, we'll use leave-one-out cross-validation (predicting one lagged vector at a time, using all the rest as library) instead of completely separate library and prediction timeseries.  However, we still have to denote segments of the pooled timeseries in order to avoid spanning separate timeseries in either prediction or library vectors.

Also, keep in mind that with CCM, prediction is in the opposite direction from normal causation theory: If we hypothesize that X is forcing or "causing" Y, then the behavior/dynamics of X leave a signature on Y.  Therefore, we try to "cross-predict" X based on the reconstructured state-space of Y.  If this cross-prediction of X from Y is positive, signficant, and convergent, we can infer causality.

```{r CCM}
# Composite segments (i.e., row indices denoting different sites' timeseries)
segments <- composite.ts %>% 
  mutate(ind = row_number()) %>% 
  group_by(site) %>% 
  summarise(first=first(ind),last=last(ind)) %>%
  select(-site) %>%
  as.matrix()

composite.ts <- composite.ts %>% select(-site) %>% as.matrix()

# first, a test: red vs. purple urchins. Test first if red urchin abundance forces purple urchin abundance. Remember, this hypothesis implies that "red" has left a signature on "purp", so we should be able to predict red based on SSR of purple. Embedding dimension will be the best that we found previously for red (E=6).
purp_xmap_red <- ccm(block=composite.ts, lib=segments, pred=segments, E=6,lib_column = "purp",target_column = "red",
                     lib_sizes = c(seq(5,55,by=2),seq(55,400,by=50)),num_samples=100,silent=TRUE)

# to look at uni- vs. bi-directional causation, we also do the inverse (purple predicting red, E=best E for purp=4)
red_xmap_purp<- ccm(composite.ts, lib=segments, pred=segments, E=4,lib_column = "red",target_column = "purp",
                     lib_sizes = c(seq(5,55,by=2),seq(55,400,by=50)),num_samples=100,silent=TRUE)

# means and sd for each library size
purp_xmap_red_means <- data.frame(ccm_means(purp_xmap_red),sd.rho=with(purp_xmap_red,tapply(rho,lib_size,sd)))
red_xmap_purp_means <- data.frame(ccm_means(red_xmap_purp),sd.rho=with(red_xmap_purp,tapply(rho,lib_size,sd)))

# plot of output
# Plot output
par(mar = c(4, 4, 1, 1))
plot(purp_xmap_red_means$lib_size, pmax(0, purp_xmap_red_means$rho), type = "l", col = "purple", 
    xlab = "Library Size", ylab = "Cross Map Skill (rho)", ylim = c(0, 0.6), 
    lwd = 2)
lines(red_xmap_purp_means$lib_size, pmax(0, red_xmap_purp_means$rho), col = "red", lwd = 2)
legend(x = "topleft", legend = c("Purple xmap Red Urchins", "Red xmap Purple Urchins"), 
    col = c("red", "blue"), lwd = 2, inset = 0.02, bty = "n", cex = 0.8)
abline(h = 0, lty = 3, col = "darkgrey", lwd = 2)

# Add CI's
lines(purp_xmap_red_means$lib_size, purp_xmap_red_means$rho + purp_xmap_red_means$sd.rho, col = "purple", 
    lty = 2, lwd = 2)
lines(purp_xmap_red_means$lib_size, purp_xmap_red_means$rho - purp_xmap_red_means$sd.rho, col = "purple", 
    lty = 2, lwd = 2)
lines(red_xmap_purp_means$lib_size, red_xmap_purp_means$rho + red_xmap_purp_means$sd.rho, col = "red", 
    lty = 2, lwd = 2)
lines(red_xmap_purp_means$lib_size, red_xmap_purp_means$rho - red_xmap_purp_means$sd.rho, col = "red", 
    lty = 2, lwd = 2)

```