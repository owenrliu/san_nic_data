---
title: "CCM_san_nic"
author: "Owen Liu"
date: "May 20, 2016"
output: html_document
---

```{r setup, include=FALSE}
library(ggplot2)
library(tidyr)
library(dplyr)
library(reshape2)
library(vegan)
library(rgdal)
library(tseries)
library(rEDM)

#### Data ####
#note: all raw data has a .dat
W_D <- getwd()

# benthic species density
#**************************************
benthdens.dat <- read.csv(file=paste(W_D,'/data/Benthic density raw data.csv',sep=''))
#fix dates in the datasets to be more readable by R
betterDates <-function(dat) {
  dates<-as.Date(as.character(dat$Date),format="%m/%d/%y")
  return(dates)
}
benthdens.dat$Date <- betterDates(benthdens.dat)
#**************************************

# Benthic and midwater fish density
#**************************************
benthfish.dat <- read.csv(paste0(W_D,'/data/Benthic fish density raw data.csv')) %>% 
  select(-JuvDensity,-Date) %>%
  rename(benth.adult = AdultDensity)
midfish.dat <- read.csv(paste0(W_D,'/data/Midwater fish density raw data.csv')) %>% 
  select(-JuvDensity,-Date) %>%
  rename(mid.adult = AdultDensity)

# joining and summing adult density
fish.dat <- full_join(benthfish.dat,midfish.dat,by=c("Station","Period","Transect","SpeciesCode")) %>%
  
  rowwise() %>%
  
  mutate(dens = sum(benth.adult,mid.adult,na.rm=T)) %>%
  
  # join station and swath columns into one unique 'site' identifier
  unite(site,Station,Transect) %>%
  
  # Rename some variables and remove extra variables
  rename(period=Period,spp=SpeciesCode) %>%
  select(-benth.adult,-mid.adult)

#*************************************
# Species Key
#*************************************
spp.key <- read.csv(file=paste(W_D,'/data/Table4_Species_sampled.csv',sep=''),stringsAsFactors = F) # All species, all surveys
spp.key.bdens <- spp.key[spp.key$DataSet=="Benthic density",] # just benthic density surveys

# better names
spp.key.bdens$name <- c("pat","red","purp","wavy","astro","derm","halc","halr","limp","paras","pis","pyc","cys","lam","ymac","youn","eis","pter","mac")

# names for fish
spp.key.fish <- spp.key %>% 
  filter(DataSet %in% c("Benthic fish density","Midwater fish density")) %>%
  select(-DataSet) %>%
  distinct()

# quick function to turn a "genus species" into an abbreviated gen.spe identifier
abbr.fish.names <- function(x) {
  temp <- strsplit(x," ")[[1]]
  g <- substr(temp[1],1,3)
  spe <- substr(temp[2],1,3)
  paste(g,spe,sep=".")
}

spp.key.fish$name <- sapply(spp.key.fish$SpeciesName,abbr.fish.names)
fish.dat <- fish.dat %>% left_join(spp.key.fish,by=c("spp"="SpeciesCode")) %>% 
  select(-spp,-SpeciesName) %>% rename(spp=name)

#**************************************

# Otter data
#***********************************
ott <- read.csv(file=paste(W_D,"/data/Table2_independent_sea_otters.csv",sep=""))
ott$Date<-as.Date(ott$Date,format="%m/%d/%Y")
# Have to manually match otter counts to periods in the benthic data, and assume population statis between periods when otters weren't counted
ott.counts.west <- c(rep(0,29),rep(10,3),9,rep(13,4),18,18,rep(20,3),24,22,20,20,30,29,29,29,29,31,31,18,18,30,34,42)
ott.counts.north <- c(rep(0,29),rep(4,3),5,rep(1,9),0,1,rep(0,7),1,1,0,0,1,4,0)
ott.counts.south <- c(rep(0,32),3,rep(0,4),2,2,rep(0,3),3,6,13,13,2,2,2,2,2,5,5,19,19,2,8,6)
ott.abun.key <- data.frame(period=sort(unique(benthdens.dat$Period)),west=ott.counts.west,north=ott.counts.north,south=ott.counts.south)

# ***********************************
# Replace species code with species name and rename some variables
benthdat <- benthdens.dat %>% 
  rename(station=Station,period=Period,date=Date,swath=Swath,dens=Density) %>%
  left_join(select(spp.key.bdens,SpeciesCode,name),by="SpeciesCode") %>%
  
  # remove unneeded columns
  select(-SpeciesCode,-date) %>%
  rename(spp=name) %>%
  arrange(spp,period,swath) %>%
  
  # join station and swath columns into one unique 'site' identifier
  unite(site,station,swath)

#*************************************
# There's one more problem, which is that there are some periods which were not sampled. It's better to make those values NAs in the data than just skipping over time periods.  This set of code expands the timeseries for each site/species to include NA density values for missing survey times.

periods.all <- data_frame(period=1:63)

# "Filling in" benthic data
sites <- sort(unique(benthdat$site))
spps <- sort(unique(benthdat$spp))
benthdat.full <- data_frame()
for(i in 1:length(sites)) {
  for(j in 1:length(spps)) {
    temp <- benthdat %>% filter(site==sites[i],spp==spps[j])
    temp <- full_join(periods.all,temp,by="period") %>% mutate(site=sites[i],spp=spps[j])
    benthdat.full <- bind_rows(benthdat.full,temp)
  }
}

# Filling in fish data
sites <- sort(unique(fish.dat$site))
spps <- sort(unique(fish.dat$spp))
fishdat.full <- data_frame()
for(i in 1:length(sites)) {
  for(j in 1:length(spps)) {
    temp <- fish.dat %>% filter(site==sites[i],spp==spps[j])
    temp <- full_join(periods.all,temp,by="period") %>% mutate(site=sites[i],spp=spps[j])
    fishdat.full <- bind_rows(fishdat.full,temp)
  }
}
rm(temp)

```

Convergent cross mapping of the time series.  Based on Sugihara et al. 2012 Science; and Clark et al. 2015 Ecology.  First we run simplex analysis to establish embedding dimension for each species.  Then we can look for nonlinearity and cross mapping.  Because the San Nicolas data is split into periods and swaths, we'll take advantage of all the data we can for each species by constructing library vectors from all records of all swaths within a station, making sure not to construct library vectors spanning two different swaths.

```{r simplex and smap}

spp.simplex.smap <- function(data,species, stations=c(1:7), lib_frac=0.5,plotout = TRUE) {
  
  # all data for a particular species
  spp.dat <- filter(data, spp==species) %>%
    
    # select only some stations (if applicable)
    separate(site,into=c("station","swath"),sep="_",remove=FALSE) %>%
    filter(station %in% stations) %>%
    arrange(site,period)
  
  # we need a record of the segments (indices of the beginning and end of each timeseries), so that simplex and s-map do not produce library or prediction vectors that span separate timeseries. This 2-column matrix denotes the row indices of the first and last record in each timeseries.
  
  segments <- spp.dat %>% mutate(ind = row_number()) %>% 
    group_by(site) %>% 
    summarise(first=first(ind),last=last(ind))
  
  # Now we can produce a random set of the segments for prediction, and use the others for the library.  This is controlled by the lib_frac parameter in the function.  The default is half (half of the vectors used for prediction, half for library)
  
   # if lib_frac FALSE, take all segments as library and predictor (triggering leave-one-out cross-validation)
  if(lib_frac==FALSE) {
    segments <- select(segments,-site)
    rndlib<-rndpred<-segments
  }
  else{
    rndlib <- segments %>% sample_frac(lib_frac,replace=F) %>% arrange(first) %>% select(-site)
    rndpred <- anti_join(segments,rndlib,by=c("first","last")) %>% arrange(first) %>% select(-site) # prediction vectors and library vectors mutually exclusive
  }

  rndlib <- as.matrix(rndlib)
  rndpred <- as.matrix(rndpred)
 
  # composite timeseries (just year and data)
  ts.mat <- as.matrix(select(spp.dat,period,dens))
  
  # Now we can finally run simplex and s-map.
  # A NOTE HERE: using option exclusion_radius allows us to also remove from the library for each prediction the concurrent years' data from the other pooled timeseries, reducing overestimation due to spatial autocorrelation. For now we'll use an exclusion radius of 1 (for simplex) and min(3,E) for smap.
  spp.simplex <- simplex(ts.mat,lib=rndlib,pred=rndpred,E=c(2:8))
  if(plotout) {
    plot(spp.simplex$E,spp.simplex$rho,type="l",xlab="Embedding Dimension (E)",ylab="Forecast Skill(rho)",main=species)
  }
  
  # find best E from simplex output
  bestE <- spp.simplex$E[which(spp.simplex$rho==max(spp.simplex$rho))]
  print(paste("Best embedding dimension is",bestE))
  
  # Prediction decay check (checking for the butterfly effect)
  spp.tp.test <- simplex(ts.mat,lib=rndlib,pred=rndpred,E=bestE,tp=1:10)
  if(plotout) {
    plot(spp.tp.test$tp,spp.tp.test$rho,type="l",xlab="Prediction Horizon (tp)",ylab="Forecast Skill(rho)",main=species)
  }
  
  # Good forecast skill, and best E (best embedding dimension) recorded.  Now we can s-map to look for nonlinearity
  spp.smap <- s_map(ts.mat,lib=rndlib,pred=rndpred,E=bestE,exclusion_radius = 1)
  if(plotout) {
    plot(spp.smap$theta,spp.smap$rho,type="l",xlab="Nonlinearity (theta)",ylab="Forecast Skill(rho)",main=species)
  }
  out <- list(bestE=bestE,simp = spp.simplex,tp=spp.tp.test,smap = spp.smap)
  return(out)
}

```

Let's apply this to a subset of species in the San Nic dataset (benthic density data first).  Let's look for species without too many zeroes, so the dynamics aren't weirdly skewed.

```{r apply simp and smap}
# What proportion of zeroes in the data for each species/site?
numzeroes <- benthdat.full %>% group_by(spp) %>% filter(dens==0 | is.na(dens)) %>% summarise(zeroes=n())
propzeroes <- benthdat.full %>% group_by(spp) %>% 
  filter(dens != 0, !is.na(dens)) %>% 
  summarise(nonzeroes=n()) %>%
  left_join(numzeroes, by="spp") %>%
  mutate(propzeroes=(zeroes/(nonzeroes+zeroes))) %>%
  arrange(propzeroes)

usable.spp <- propzeroes$spp[1:14]

# Lists to store simplex and smap output for each species
spp.simp.list <- list()
b.bestE <- data_frame(species = usable.spp,E=NA)
spp.tp.list <- list()
spp.smap.list <- list()

for(i in 1:length(usable.spp)) {
  sppname <- usable.spp[i]
  temp <- spp.simplex.smap(data=benthdat.full,species=usable.spp[i],plotout=FALSE)
  spp.simp.list[[sppname]] <- temp$simp
  spp.tp.list[[sppname]] <- temp$tp
  spp.smap.list[[sppname]] <- temp$smap
  b.bestE[i,"E"] <- temp$bestE
  rm(temp)
}

# plot simplex output
par(mfrow=c(2,2))

for(i in 1:length(spp.simp.list)) {
  sppname <- names(spp.simp.list)[i]
  df <- spp.simp.list[[i]]
  plot(df$E,df$rho,type="l",xlab="Embedding Dimension (E)",ylab="Forecast Skill(rho)",main=paste(sppname,"simplex"))
}

#plot prediction horizons
plot.new()
for(i in 1:length(spp.tp.list)) {
  sppname <- names(spp.tp.list)[i]
  df <- spp.tp.list[[i]]
  plot(df$tp,df$rho,type="l",xlab="Prediction Horizon (tp)",ylab="Forecast Skill(rho)",main=paste(sppname,"prediction decay"))
}
# plot smap output
plot.new()

for(i in 1:length(spp.smap.list)) {
  sppname <- names(spp.smap.list)[i]
  df <- spp.smap.list[[i]]
  plot(df$theta,df$rho,type="l",xlab="Nonlinearity (theta)",ylab="Forecast Skill(rho)",main=paste(sppname,"smap"))
}
par(mfrow=c(1,1))
```

To do cross-mapping, it really helps to have the data organized in a way such that the time indices are all the same across all species.  So here, we'll make a large composites timeseries with the appended timeseries from all sites, but with columns being species.  We can use this composite for multivariate prediction and cross-mapping.

```{r composite timeseries}
comp.ts.benth <- filter(benthdat.full, spp %in% usable.spp) %>%
  dcast(period + site ~ spp,value.var="dens") %>%
  arrange(site)
```

Now we have vertically "stacked" timeseries across species.  Time to run CCM.  For these, we'll use leave-one-out cross-validation (predicting one lagged vector at a time, using all the rest as library) instead of completely separate library and prediction timeseries.  However, we still have to denote segments of the pooled timeseries in order to avoid spanning separate timeseries in either prediction or library vectors.

Also, keep in mind that with CCM, prediction is in the opposite direction from normal causation theory: If we hypothesize that X is forcing or "causing" Y, then the behavior/dynamics of X leave a signature on Y.  Therefore, we try to "cross-predict" X based on the reconstructured state-space of Y.  If this cross-prediction of X from Y is positive, signficant, and convergent, we can infer causality.

```{r CCM}
# Composite segments (i.e., row indices denoting different sites' timeseries)
segments <- comp.ts.benth %>% 
  mutate(ind = row_number()) %>% 
  group_by(site) %>% 
  summarise(first=first(ind),last=last(ind)) %>%
  select(-site) %>%
  as.matrix()

comp.ts.benth <- comp.ts.benth %>% select(-site) %>% as.matrix()

# first, a test: red vs. purple urchins. Test first if red urchin abundance forces purple urchin abundance. Remember, this hypothesis implies that "red" has left a signature on "purp", so we should be able to predict red based on SSR of purple. Embedding dimension will be the best that we found previously for red (E=6).
purp_xmap_red <- ccm(block=comp.ts.benth, lib=segments, pred=segments, E=6,lib_column = "purp",target_column = "red",
                     lib_sizes = c(seq(5,55,by=2),seq(55,400,by=50)),num_samples=100,silent=TRUE)

# to look at uni- vs. bi-directional causation, we also do the inverse (purple predicting red, E=best E for purp=4)
red_xmap_purp<- ccm(comp.ts.benth, lib=segments, pred=segments, E=4,lib_column = "red",target_column = "purp",
                     lib_sizes = c(seq(5,55,by=2),seq(55,400,by=50)),num_samples=100,silent=TRUE)

# means and sd for each library size
purp_xmap_red_means <- data.frame(ccm_means(purp_xmap_red),sd.rho=with(purp_xmap_red,tapply(rho,lib_size,sd)))
red_xmap_purp_means <- data.frame(ccm_means(red_xmap_purp),sd.rho=with(red_xmap_purp,tapply(rho,lib_size,sd)))

# plot of output
# Plot output
par(mar = c(4, 4, 1, 1))
plot(purp_xmap_red_means$lib_size, pmax(0, purp_xmap_red_means$rho), type = "l", col = "purple", 
    xlab = "Library Size", ylab = "Cross Map Skill (rho)", ylim = c(0, 0.6), 
    lwd = 2)
lines(red_xmap_purp_means$lib_size, pmax(0, red_xmap_purp_means$rho), col = "red", lwd = 2)
legend(x = "topleft", legend = c("Purple xmap Red Urchins", "Red xmap Purple Urchins"), 
    col = c("purple", "red"), lwd = 2, inset = 0.02, bty = "n", cex = 0.8)
abline(h = 0, lty = 3, col = "darkgrey", lwd = 2)

# Add CI's
lines(purp_xmap_red_means$lib_size, purp_xmap_red_means$rho + purp_xmap_red_means$sd.rho, col = "purple", 
    lty = 2, lwd = 2)
lines(purp_xmap_red_means$lib_size, purp_xmap_red_means$rho - purp_xmap_red_means$sd.rho, col = "purple", 
    lty = 2, lwd = 2)
lines(red_xmap_purp_means$lib_size, red_xmap_purp_means$rho + red_xmap_purp_means$sd.rho, col = "red", 
    lty = 2, lwd = 2)
lines(red_xmap_purp_means$lib_size, red_xmap_purp_means$rho - red_xmap_purp_means$sd.rho, col = "red", 
    lty = 2, lwd = 2)

```

Red urchins and macrocystis

```{r red and macro}
mac_xmap_red <- ccm(block=comp.ts.benth, lib=segments, pred=segments, E=6,lib_column = "mac",target_column = "red",
                     lib_sizes = c(seq(5,55,by=2),seq(55,400,by=50)),num_samples=100,silent=TRUE)

# to look at uni- vs. bi-directional causation, we also do the inverse (mac predicting red, E=best E for mac=4)
red_xmap_mac<- ccm(comp.ts.benth, lib=segments, pred=segments, E=6,lib_column = "red",target_column = "mac",
                     lib_sizes = c(seq(5,55,by=2),seq(55,400,by=50)),num_samples=100,silent=TRUE)

# means and sd for each library size
mac_xmap_red_means <- data.frame(ccm_means(mac_xmap_red),sd.rho=with(mac_xmap_red,tapply(rho,lib_size,sd)))
red_xmap_mac_means <- data.frame(ccm_means(red_xmap_mac),sd.rho=with(red_xmap_mac,tapply(rho,lib_size,sd)))

# plot of output
# Plot output
par(mar = c(4, 4, 1, 1))
plot(mac_xmap_red_means$lib_size, pmax(0, mac_xmap_red_means$rho), type = "l", col = "darkgreen", 
    xlab = "Library Size", ylab = "Cross Map Skill (rho)", ylim = c(0, 0.6), 
    lwd = 2)
lines(red_xmap_mac_means$lib_size, pmax(0, red_xmap_mac_means$rho), col = "red", lwd = 2)
legend(x = "topleft", legend = c("Macrocystis xmap Red Urchins", "Red Urchins xmap Macrocystis"), 
    col = c("darkgreen", "red"), lwd = 2, inset = 0.02, bty = "n", cex = 0.8)
abline(h = 0, lty = 3, col = "darkgrey", lwd = 2)

# Add CI's
lines(mac_xmap_red_means$lib_size, mac_xmap_red_means$rho + mac_xmap_red_means$sd.rho, col = "darkgreen", 
    lty = 2, lwd = 2)
lines(mac_xmap_red_means$lib_size, mac_xmap_red_means$rho - mac_xmap_red_means$sd.rho, col = "darkgreen", 
    lty = 2, lwd = 2)
lines(red_xmap_mac_means$lib_size, red_xmap_mac_means$rho + red_xmap_mac_means$sd.rho, col = "red", 
    lty = 2, lwd = 2)
lines(red_xmap_mac_means$lib_size, red_xmap_mac_means$rho - red_xmap_mac_means$sd.rho, col = "red", 
    lty = 2, lwd = 2)

```

Purple urchins and macrocystis

```{r purple and macro}
mac_xmap_purp<- ccm(comp.ts.benth, lib=segments, pred=segments, E=4,lib_column = "mac",target_column = "purp",
                     lib_sizes = c(seq(5,55,by=2),seq(55,400,by=50)),num_samples=100,silent=TRUE)

# to look at uni- vs. bi-directional causation, we also do the inverse (purp pmacicting mac, E=best E for purp=4)
purp_xmap_mac <- ccm(block=comp.ts.benth, lib=segments, pred=segments, E=6,lib_column = "purp",target_column = "mac",
                     lib_sizes = c(seq(5,55,by=2),seq(55,400,by=50)),num_samples=100,silent=TRUE)

# means and sd for each library size
purp_xmap_mac_means <- data.frame(ccm_means(purp_xmap_mac),sd.rho=with(purp_xmap_mac,tapply(rho,lib_size,sd)))
mac_xmap_purp_means <- data.frame(ccm_means(mac_xmap_purp),sd.rho=with(mac_xmap_purp,tapply(rho,lib_size,sd)))

# plot of output
# Plot output
par(mar = c(4, 4, 1, 1))
plot(purp_xmap_mac_means$lib_size, pmax(0, purp_xmap_mac_means$rho), type = "l", col = "purple", 
    xlab = "Library Size", ylab = "Cross Map Skill (rho)", ylim = c(0, 0.8), 
    lwd = 2)
lines(mac_xmap_purp_means$lib_size, pmax(0, mac_xmap_purp_means$rho), col = "darkgreen", lwd = 2)
legend(x = "topleft", legend = c("Purple Urchins xmap Macrocystis", "Macrocystis xmap Purple Urchins"), 
    col = c("purple", "darkgreen"), lwd = 2, inset = 0.02, bty = "n", cex = 0.8)
abline(h = 0, lty = 3, col = "darkgrey", lwd = 2)

# Add CI's
lines(purp_xmap_mac_means$lib_size, purp_xmap_mac_means$rho + purp_xmap_mac_means$sd.rho, col = "purple", 
    lty = 2, lwd = 2)
lines(purp_xmap_mac_means$lib_size, purp_xmap_mac_means$rho - purp_xmap_mac_means$sd.rho, col = "purple", 
    lty = 2, lwd = 2)
lines(mac_xmap_purp_means$lib_size, mac_xmap_purp_means$rho + mac_xmap_purp_means$sd.rho, col = "darkgreen", 
    lty = 2, lwd = 2)
lines(mac_xmap_purp_means$lib_size, mac_xmap_purp_means$rho - mac_xmap_purp_means$sd.rho, col = "darkgreen", 
    lty = 2, lwd = 2)
```

### Pairwise CCM
Let's look at cross-mapping of all pairs of species

```{r xmap benthic spp}
ncol <- dim(comp.ts.benth)[2]-1
col.names <- colnames(comp.ts.benth)[2:15]
xmap_mat <- array(NA,dim=c(ncol,ncol),dimnames=list(col.names,col.names))
# matrix to store a bootstrapped p-value, measuring the probability that a given xmap is greater than zero (calculated as 
# 1 minus the number of positive results for rho divided by the number of iterations)
p1.mat <- array(NA,dim=c(ncol,ncol),dimnames=list(col.names,col.names))

# similarly, matrix to store a bootstrapped p-value, this time a t-test value between library size 10 and library size 500, to see if the rho at large library is significantly greater than the rho at small library size (i.e., looking for convergence).  If rho does not converge with library length, it may be a sign of synchrony.
p2.mat <- array(NA,dim=c(ncol,ncol),dimnames=list(col.names,col.names))

# if both p1 and p2 are positive, indicate overall significant causal signal
ptot.mat <- array(NA,dim=c(ncol,ncol),dimnames=list(col.names,col.names))

for(i in 1:ncol) {
  for(j in 1:ncol) {
    if(i != j) {
      tempE=b.bestE$E[b.bestE$species==col.names[j]]
      temp <- ccm(comp.ts.benth,E=tempE,lib=segments,pred=segments,lib_column = 1+i,target_column = 1+j,
                  lib_sizes = c(10,500),replace=T,silent=T)
      # mean rho at library size 500
      rhomean <- temp %>% filter(lib_size==500) %>% ccm_means()
      xmap_mat[i,j] <- rhomean$rho
      
      # first p-value (greater than zero? at largest library size)
      p1 <- temp %>% filter(lib_size==500) %>% mutate(pos=ifelse(rho>0,1,0)) %>% summarise(p=(1-sum(pos)/n()))
      p1.mat[i,j] <- as.numeric(p1)
      
      # second p-value (rho at lib-size 500 greater than rho at lib-size 10?)
      p2 <- t.test(temp$rho[temp$lib_size==10],temp$rho[temp$lib_size==500])$p.value
      p2.mat[i,j] <- as.numeric(p2)
      
      # overall significance
      ptot.mat[i,j] <- ifelse(p1<0.05 & p2<0.05,1,0)
    }
  }
}

# dendrogram (preliminary)
xmap_mat_dist <- (1-xmap_mat)
xmap_mat_dist <- as.dist(xmap_mat_dist)
test.clust<- hclust(xmap_mat_dist,method="ward.D2")
test.clust<-reorder(test,xmap_mat_dist)
plot(test.clust,hang=-0.1)
rect.hclust(test.clust,k=4,border=c("red","blue","darkgreen","purple"))

dend <- as.dendrogram(test)
heatmap(as.matrix(xmap_mat_dist),Rowv=dend,symm=TRUE)

## WARNING: this takes awhile to run
```

With this output, we can look at the web of significant dynamic causation.  Here we display both the interaction web (which species' dynamics force which other species' dynamics), and calculate a "dynamic centrality" score, which measures the extent to which a species is dynamically causing, or caused by, other species' dynamics.


```{r dynamic centrality}
# number of causes vs. caused by:
connections <- data.frame(spp=col.names,into=NA,out=NA)
for(i in 1:length(col.names)) {
  species <- col.names[i]
  connections$into[i] <- sum(ptot.mat[species,],na.rm=T)
  connections$out[i] <- sum(ptot.mat[,species],na.rm=T)
}

# Interaction web. Arrow from A to B indicates significant causal signal in CCM analysis.
library(igraph)
g <- graph.adjacency(t(ptot.mat))
plot(g)

# Calculate a "centrality" score
connections <- connections %>% mutate(score=out+into) %>% mutate(centrality=score/max(score),rank=row_number(desc(score))) %>% arrange(desc(centrality))
ggplot(connections,aes(x=rank,y=centrality))+geom_text(aes(label=spp)) +
  ggtitle("Dynamic Centrality of Kelp Forest Species") +
  xlab("Species Rank") +
  ylab("Relative Centrality") +
  theme_minimal()
```


## Simplex and S Map, Kelp Forest Fish
Let's look at the fish data now, and do something similar.

```{r simplex and smap fish data}
# What proportion of zeroes in the data for each species/site?
f.numzeroes <- fishdat.full %>% group_by(spp) %>% filter(dens==0 | is.na(dens)) %>% summarise(zeroes=n())
f.propzeroes <- fishdat.full %>% group_by(spp) %>% 
  filter(dens != 0,!is.na(dens)) %>% 
  summarise(nonzeroes=n()) %>%
  left_join(f.numzeroes, by="spp") %>%
  mutate(propzeroes=(zeroes/(nonzeroes+zeroes))) %>%
  arrange(propzeroes)

# We'll choose a subset of fish species to run analyses on

f.usable.spp <- f.propzeroes$spp[1:16]

# Lists to store simplex and smap output for each species
f.spp.simp.list <- list()
f.bestE <- data_frame(species = f.usable.spp,E=NA)
f.spp.tp.list <- list()
f.spp.smap.list <- list()

for(i in 1:length(f.usable.spp)) {
  sppname <- as.character(f.usable.spp[i])
  temp <- spp.simplex.smap(data=fishdat.full,species=sppname,lib_frac=F,plotout=FALSE)
  f.spp.simp.list[[sppname]] <- temp$simp
  f.spp.tp.list[[sppname]] <- temp$tp
  f.spp.smap.list[[sppname]] <- temp$smap
  f.bestE[i,"E"] <- temp$bestE
  rm(temp)
}

# plot simplex output
par(mfrow=c(2,2))

for(i in 1:length(f.spp.simp.list)) {
  sppname <- names(f.spp.simp.list)[i]
  df <- f.spp.simp.list[[i]]
  plot(df$E,df$rho,type="l",xlab="Embedding Dimension (E)",ylab="Forecast Skill(rho)",main=paste(sppname,"simplex"))
}

#plot prediction horizons
plot.new()
for(i in 1:length(f.spp.tp.list)) {
  sppname <- names(f.spp.tp.list)[i]
  df <- f.spp.tp.list[[i]]
  plot(df$tp,df$rho,type="l",xlab="Prediction Horizon (tp)",ylab="Forecast Skill(rho)",main=paste(sppname,"prediction decay"))
}
# plot smap output
plot.new()

for(i in 1:length(f.spp.smap.list)) {
  sppname <- names(f.spp.smap.list)[i]
  df <- f.spp.smap.list[[i]]
  plot(df$theta,df$rho,type="l",xlab="Nonlinearity (theta)",ylab="Forecast Skill(rho)",main=paste(sppname,"smap"))
}
par(mfrow=c(1,1))

```

Now let's do CCM, with ALL the species (benthic and fish).  First, a combined timeseries block.

```{r CCM all species}
# Benthic species
comp.ts.benth <- filter(benthdat.full, spp %in% usable.spp) %>%
  dcast(period + site ~ spp,value.var="dens") %>%
  arrange(site)

# Fish species
comp.ts.fish <- filter(fishdat.full, spp %in% f.usable.spp) %>%
  dcast(period + site ~ spp,value.var="dens",fun.aggregate=mean) %>%
  arrange(site) %>%
  select(-site,-period)

# all species. Benthic has two extra "sites" relative to the fish species, so we'll remove these from prediction/library
comp.ts.all <- comp.ts.benth %>% filter(site != "6_39R",site != "6_22R") %>% bind_cols(comp.ts.fish)

# and the relevant segments (to prevent spanning different time-series)
segments <- comp.ts.all %>% 
  mutate(ind = row_number()) %>% 
  group_by(site) %>% 
  summarise(first=first(ind),last=last(ind)) %>%
  select(-site) %>%
  as.matrix()

comp.ts.all <- comp.ts.all %>% select(-site) %>% as.matrix()

```

Now we run CCM on the entire combined timeseries (pairwise, as before).  This will computationally take a long time.

```{r CCM all species}
ncol <- dim(comp.ts.all)[2]-1
col.names <- colnames(comp.ts.all)[2:(ncol+1)]
xmap_mat <- array(NA,dim=c(ncol,ncol),dimnames=list(col.names,col.names))
# matrix to store a bootstrapped p-value, measuring the probability that a given xmap is greater than zero (calculated as 
# 1 minus the number of positive results for rho divided by the number of iterations)
p1.mat <- array(NA,dim=c(ncol,ncol),dimnames=list(col.names,col.names))

# similarly, matrix to store a bootstrapped p-value, this time a t-test value between library size 10 and library size 500, to see if the rho at large library is significantly greater than the rho at small library size (i.e., looking for convergence).  If rho does not converge with library length, it may be a sign of synchrony.
p2.mat <- array(NA,dim=c(ncol,ncol),dimnames=list(col.names,col.names))

# if both p1 and p2 are positive, indicate overall significant causal signal
ptot.mat <- array(NA,dim=c(ncol,ncol),dimnames=list(col.names,col.names))

# Bind best Es for benthic and fish
bestE <- bind_rows(b.bestE,f.bestE)


for(i in 1:ncol) {
  for(j in 1:ncol) {
    if(i != j) {
      tempE=bestE$E[bestE$species==col.names[j]]
      temp <- ccm(comp.ts.all,lib=segments,pred=segments,E=tempE,lib_column = 1+i,target_column = 1+j,
                  lib_sizes = c(10,500),replace=T,silent=T)
      # mean rho at library size 500
      rhomean <- temp %>% filter(lib_size==500) %>% ccm_means()
      xmap_mat[i,j] <- rhomean$rho
      
      # first p-value (greater than zero? at largest library size)
      p1 <- temp %>% filter(lib_size==500) %>% mutate(pos=ifelse(rho>0,1,0)) %>% summarise(p=(1-sum(pos)/n()))
      p1.mat[i,j] <- as.numeric(p1)
      
      # second p-value (rho at lib-size 500 greater than rho at lib-size 10?)
      p2 <- t.test(temp$rho[temp$lib_size==10],temp$rho[temp$lib_size==500])$p.value
      p2.mat[i,j] <- as.numeric(p2)
      
      # overall significance
      ptot.mat[i,j] <- ifelse(p1<0.05 & p2<0.05,1,0)
    }
  }
}

# dendrogram (preliminary)
xmap_mat_dist <- (1-xmap_mat)
xmap_mat_dist <- as.dist(xmap_mat_dist)
test.clust<- hclust(xmap_mat_dist,method="ward.D2")
test.clust<-reorder(test.clust,xmap_mat_dist)
plot(test.clust,hang=-0.1)
rect.hclust(test.clust,k=4,border=c("red","blue","darkgreen","purple"))

dend <- as.dendrogram(test.clust)
heatmap(as.matrix(xmap_mat_dist),Rowv=dend,symm=TRUE)

## WARNING: this takes awhile to run

```

Dynamic centrality for entire assemblage:

```{r dynamic centrality}
# number of causes vs. caused by:
connections.all <- data.frame(spp=col.names,into=NA,out=NA)
for(i in 1:length(col.names)) {
  species <- col.names[i]
  connections.all$into[i] <- sum(ptot.mat[species,],na.rm=T)
  connections.all$out[i] <- sum(ptot.mat[,species],na.rm=T)
}

# Interaction web. Arrow from A to B indicates significant causal signal in CCM analysis.
library(igraph)
g <- graph.adjacency(t(ptot.mat))
plot(g)

# Calculate a "centrality" score
connections.all <- connections.all %>% mutate(score=out+into) %>% mutate(centrality=score/max(score),rank=row_number(desc(score))) %>% arrange(desc(centrality))
ggplot(connections.all,aes(x=rank,y=centrality))+geom_text(aes(label=spp),size=3) +
  ggtitle("Dynamic Centrality of Kelp Forest Species") +
  xlab("Species Rank") +
  ylab("Relative Centrality") +
  theme_minimal()
ggsave("centrality.png",width=10,height=5)
```

We should add temperature and maybe ENSO